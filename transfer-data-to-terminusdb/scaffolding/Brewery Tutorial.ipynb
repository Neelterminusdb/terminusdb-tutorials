{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e527090b",
   "metadata": {},
   "source": [
    "# Brewery Tutorial\n",
    "__[Open Brewery](https://www.openbrewerydb.org)__ DB is a free dataset and API with public information on breweries, cideries, brewpubs, and bottleshops. The goal of Open Brewery DB is to maintain an open-source, community-driven dataset and provide a public API. Datasets provided by the project are available in the following formats:\n",
    "- __[CSV](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.csv)__\n",
    "- __[JSON](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.json)__\n",
    "- __[PostgreSQL SQL](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.sql)__\n",
    "\n",
    "For this tutorial, CSV will be used.\n",
    "\n",
    "TerminusDB Server must be installed on your system before running the Python script. Follow the instructions on __[terminusdb-bootstrap](https://github.com/terminusdb/terminusdb-bootstrap)__. terminusdb-server will be running as a Docker container on http://127.0.0.1:6363.\n",
    "\n",
    "Python client of TerminusDB is also required. It can be installed from source or through `pip`, you can follow the instructions in the __[repository](https://github.com/terminusdb/terminusdb-client-python)__. When running `pip install terminusdb-client[dataframe]` you will get pandas that is required for reading and import data from CSV files. If installed from source, run `pip install pandas`. tdqm is used for adding a progress bar, run `pip install tqdm` to install it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe33cde",
   "metadata": {},
   "source": [
    "## Scaffolding\n",
    "Database and schema creation in TerminusDB can be managed through the scaffolding tool available from the command line.\n",
    "\n",
    "- Create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminusdb startproject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b7c7d",
   "metadata": {},
   "source": [
    "This command will create a schema template (̣̣`schema.py`) and configuration file (`settings.py`) into current working directory. `settings.py` must be customized with the name of the database for the project. `schema.py`  \n",
    "must be edited and schema definition replaced according to the data imported from the CSV file.\n",
    "\n",
    "- Update schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminusdb commit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12675af5",
   "metadata": {},
   "source": [
    "Database will be created if not exists and connection established. Schema will be updated in TerminusDB.\n",
    "\n",
    "- Sync schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminusdb sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdea89f",
   "metadata": {},
   "source": [
    "`schema.py` will be updated with database schema\n",
    "\n",
    "- Delete database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c53255",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminusdb deletedb database_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304d874",
   "metadata": {},
   "source": [
    "## Schema creation\n",
    "The dataset has the following columns:\n",
    "- obdb_id\n",
    "- name\n",
    "- brewery_type\n",
    "- street\n",
    "- address_2\n",
    "- address_3\n",
    "- city\n",
    "- state\n",
    "- county_province\n",
    "- postal_code\n",
    "- website_url\n",
    "- phone\n",
    "- created_at\n",
    "- updated_at\n",
    "- country\n",
    "- longitude\n",
    "- latitude\n",
    "- tags\n",
    "\n",
    "Some of which are optional and rarely have a value assigned and can be omitted when creating the schema and importing the values.\n",
    "\n",
    "Analyzing the dataset:\n",
    "\n",
    "- A brewery has *name*, *type*, *address*, *phone* and *website url*\n",
    "- A brewery can be any of eleven different types (micro, nano, regional, brewpub, large, planning, bar, contract, proprietor, closed)\n",
    "- An address is a group of values that include *street*, *city*, *postal code* and *coordinates*\n",
    "- A city is located in a state\n",
    "- A state is part of a country\n",
    "- Coordinates are a pair of values, longitude and latitude\n",
    "\n",
    "Based on what's described above, the following documents are created, each class represents a document in the schema except Brewery Type that is an enum:\n",
    "- Brewery\n",
    "- Brewrey_Type\n",
    "- Address\n",
    "- City\n",
    "- State\n",
    "- Country\n",
    "- Coordinates\n",
    "\n",
    "IDs are created using `ValueHashKey` or `RandomKey`.\n",
    "\n",
    "`schema.py` must be customized according to the documents required and values imported from the CSV file.\n",
    "\n",
    "Don't forget to commit and sync the schema once changes are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from terminusdb_client.woqlschema import (\n",
    "    DocumentTemplate,\n",
    "    EnumTemplate,\n",
    "    RandomKey,\n",
    "    ValueHashKey,\n",
    ")\n",
    "\n",
    "\n",
    "class Address(DocumentTemplate):\n",
    "    _subdocument = []\n",
    "    city: \"City\"\n",
    "    coordinates: List[\"Coordinates\"]\n",
    "    postal_code: str\n",
    "    street: str\n",
    "\n",
    "\n",
    "class Brewery(DocumentTemplate):\n",
    "    _key = RandomKey()\n",
    "    address_of: \"Address\"\n",
    "    name: str\n",
    "    phone: str\n",
    "    type_of: \"Brewery_Type\"\n",
    "    website_url: str\n",
    "\n",
    "\n",
    "class Brewery_Type(EnumTemplate):\n",
    "    micro = ()\n",
    "    nano = ()\n",
    "    regional = ()\n",
    "    brewpub = ()\n",
    "    large = ()\n",
    "    planning = ()\n",
    "    bar = ()\n",
    "    contract = ()\n",
    "    proprietor = ()\n",
    "    closed = ()\n",
    "    taproom = ()\n",
    "\n",
    "\n",
    "class City(DocumentTemplate):\n",
    "    _key = ValueHashKey()\n",
    "    name: str\n",
    "    state: \"State\"\n",
    "\n",
    "\n",
    "class Coordinates(DocumentTemplate):\n",
    "    _key = RandomKey()\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "\n",
    "\n",
    "class Country(DocumentTemplate):\n",
    "    _key = ValueHashKey()\n",
    "    name: str\n",
    "\n",
    "\n",
    "class State(DocumentTemplate):\n",
    "    _key = ValueHashKey()\n",
    "    country: \"Country\"\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913681dd",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "For transfering data from a CSV file to a TerminusDB database, the Python client of TerminusDB and pandas are required. A progress bar is added to the script using tqdm. To import these libraries, add the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfec1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from terminusdb_client import WOQLQuery, WOQLClient\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e81415",
   "metadata": {},
   "source": [
    "## Database management\n",
    "Using the Python client:\n",
    "- Establish a connection to TerminusDB\n",
    "- Import data from CSV file\n",
    "- Print data from TerminusDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    db_id = \"open_brewery\"\n",
    "    url = \"https://raw.githubusercontent.com/openbrewerydb/openbrewerydb/master/breweries.csv\"\n",
    "    client = WOQLClient(\"http://127.0.0.1:6363\")\n",
    "    client.connect()\n",
    "    client.set_db(db_id)\n",
    "    insert_data(client, url)\n",
    "    results = client.get_all_documents(graph_type=\"instance\", count=2)\n",
    "    print(\"\\nRESULTS\\n\", list(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92700b0e",
   "metadata": {},
   "source": [
    "## Transfer data\n",
    "pandas provides built-in functions that make it simple to read and extract data from a CSV file. `read_csv` receives the path of the file as parameter, it can be a URL or a local file. Columns can be specified if not all are required, with `usecols`, `loc` method or `iloc` method.\n",
    "\n",
    "As some cells in the CSV don't have a value, when importing data it would be required to replace `NULL` values with '' if an integer or float is expected instead. `fillna` must be called to avoid `Not a number` errors.\n",
    "\n",
    "Before transfering data to TerminusDB, headers and stats of the dataset are printed, all columns in the dataset are included. Output of `df.column.values` and `df.describe(include='all')` is printed to obtain that information. \n",
    "\n",
    "Then, only required columns are selected using `loc` method and NULL values are replaced by calling `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c568230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(client, url):\n",
    "    all_breweries = []\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"HEADERS\\n\", list(df.columns.values))\n",
    "    print(\"\\nSTATS\\n\", df.describe(include='all'), \"\\n\\nPROGRESS\")\n",
    "    selection = df.loc[:, ['name', 'brewery_type', 'street', 'city', 'state', 'postal_code', 'website_url','phone', 'country', 'longitude', 'latitude']]\n",
    "    selection = selection.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63b70e",
   "metadata": {},
   "source": [
    "For importing data, a for loop is used to iterate through the values in the CSV, create objects for each document in the schema, assign values to the corresponding variables, and append these values to the `all_breweries` list. A progress bar is added with tqdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for index, row in tqdm(selection.iterrows(), total=df.shape[0], desc='Reading data'):\n",
    "        country = schema.Country()\n",
    "        country.name = row['country']\n",
    "        state = schema.State()\n",
    "        state.name = row['state']\n",
    "        state.country = country\n",
    "        city = schema.City()\n",
    "        city.name = row['city']\n",
    "        city.state = state\n",
    "        address = schema.Address()\n",
    "        address.street = row['street']\n",
    "        address.city = city\n",
    "        address.postal_code = row['postal_code']\n",
    "        address.coordinates = [str(row['longitude']), str(row['latitude'])]\n",
    "        brewery = schema.Brewery()\n",
    "        brewery.type_of = schema.Brewery_Type[row['brewery_type']]\n",
    "        brewery.address_of = address\n",
    "        brewery.phone = row['phone']\n",
    "        brewery.website_url = row['website_url']\n",
    "        all_breweries.append(brewery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c8cb1",
   "metadata": {},
   "source": [
    "Insert the `all_breweries` list into TerminusDB, with ``insert_document`. A progress bar is added with tdqm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df442d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with tqdm(total=1, desc='Transfering data') as pbar:\n",
    "        client.insert_document(all_breweries,\n",
    "                               commit_msg=\"Adding all breweries\")\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
