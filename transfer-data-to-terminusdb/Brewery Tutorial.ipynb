{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e527090b",
   "metadata": {},
   "source": [
    "# Brewery Tutorial\n",
    "__[Open Brewery](https://www.openbrewerydb.org)__ DB is a free dataset and API with public information on breweries, cideries, brewpubs, and bottleshops. The goal of Open Brewery DB is to maintain an open-source, community-driven dataset and provide a public API. Datasets provided by the project are available in the following formats:\n",
    "- __[CSV](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.csv)__\n",
    "- __[JSON](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.json)__\n",
    "- __[PostgreSQL SQL](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.sql)__\n",
    "\n",
    "For this tutorial, CSV will be used.\n",
    "\n",
    "TerminusDB Server must be installed on your system before running the Python script. Follow the instructions on __[terminusdb-bootstrap](https://github.com/terminusdb/terminusdb-bootstrap)__. terminusdb-server will be running as a Docker container on http://127.0.0.1:6363.\n",
    "\n",
    "Python client of TerminusDB is also required. It can be installed from source or through `pip`, you can follow the instructions in the __[repository](https://github.com/terminusdb/terminusdb-client-python)__. When running `pip install terminusdb-client[dataframe]` you will get pandas that is required for reading and import data from CSV files. If installed from source, run `pip install pandas`. tdqm is used for adding a progress bar, run `pip install tqdm` to install it.\n",
    "\n",
    "## Import libraries\n",
    "For transfering data from a CSV file to a TerminusDB database, the Python client of TerminusDB and pandas are required. A progress bar is added to the script using tqdm. To import these libraries, add the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfec1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from terminusdb_client import WOQLQuery, WOQLClient\n",
    "from terminusdb_client.woqlschema.woql_schema import (\n",
    "    DocumentTemplate,\n",
    "    WOQLSchema,\n",
    "    ValueHashKey,\n",
    "    HashKey,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e81415",
   "metadata": {},
   "source": [
    "## Database management\n",
    "TerminusDB Server must be installed on your system before running the Python script. Follow the instructions on __[terminusdb-bootstrap](https://github.com/terminusdb/terminusdb-bootstrap)__. terminusdb-server will be running as a Docker container on http://127.0.0.1:6363.\n",
    "\n",
    "Using the Python client:\n",
    "- Establish a connection to TerminusDB\n",
    "- Create a database named *open_brewery*\n",
    "- Insert schema into database\n",
    "- Import data from CSV file\n",
    "- Print data from TerminusDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    db_id = \"open_brewery\"\n",
    "    url = \"https://raw.githubusercontent.com/openbrewerydb/openbrewerydb/master/breweries.csv\"\n",
    "    client = WOQLClient(\"http://127.0.0.1:6363\")\n",
    "    client.connect()\n",
    "    try:\n",
    "        client.create_database(db_id, accountid=\"admin\", label = \"Open Brewery Graph\", description = \"Create a graph with brewery data\")\n",
    "    except Exception:\n",
    "        client.set_db(db_id)\n",
    "    client.insert_document(my_schema.to_dict(),\n",
    "                           graph_type=\"schema\",\n",
    "                           commit_msg=\"I am checking in the schema\")\n",
    "    insert_data(client, url)\n",
    "    results = client.get_all_documents(graph_type=\"instance\", count=2)\n",
    "    print(\"\\nRESULTS\\n\", list(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304d874",
   "metadata": {},
   "source": [
    "## Schema creation\n",
    "The dataset has the following columns:\n",
    "- obdb_id\n",
    "- name\n",
    "- brewery_type\n",
    "- street\n",
    "- address_2\n",
    "- address_3\n",
    "- city\n",
    "- state\n",
    "- county_province\n",
    "- postal_code\n",
    "- website_url\n",
    "- phone\n",
    "- created_at\n",
    "- updated_at\n",
    "- country\n",
    "- longitude\n",
    "- latitude\n",
    "- tags\n",
    "\n",
    "Some of which are optional and rarely have a value assigned and can be omitted when creating the schema and importing the values.\n",
    "\n",
    "Analyzing the dataset:\n",
    "\n",
    "- A brewery has *name*, *type*, *address*, *phone* and *website url*\n",
    "- A brewery can be any of eleven different types (micro, nano, regional, brewpub, large, planning, bar, contract, proprietor, closed)\n",
    "- An address is a group of values that include *street*, *city*, *postal code* and *coordinates*\n",
    "- A city is located in a state\n",
    "- A state is part of a country\n",
    "- Coordinates are a pair of values, longitude and latitude\n",
    "\n",
    "Based on what's described above, the following documents are created, each class represents a document in the schema except Brewery Type that is an enum:\n",
    "- Brewery\n",
    "- Brewrey_Type\n",
    "- Address\n",
    "- City\n",
    "- State\n",
    "- Country\n",
    "- Coordinates\n",
    "\n",
    "IDs are created using `ValueHashKey` or `HashKey`. `my_schema` is a `WOQLSchema` object that contains the schema itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = WOQLSchema()\n",
    "\n",
    "class Coordinates(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    longitude: float\n",
    "    latitude: float\n",
    "\n",
    "class Brewery_Type(EnumTemplate):\n",
    "    _schema = my_schema\n",
    "    micro = ()\n",
    "    nano = ()\n",
    "    regional = ()\n",
    "    brewpub = ()\n",
    "    large = ()\n",
    "    planning = ()\n",
    "    bar = ()\n",
    "    contract = ()\n",
    "    proprietor = ()\n",
    "    closed = ()\n",
    "    taproom = ()\n",
    "\n",
    "class Country(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    _key = ValueHashKey()\n",
    "    name: str\n",
    "\n",
    "class State(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    _key = ValueHashKey()\n",
    "    name: str\n",
    "    country: Country\n",
    "\n",
    "class City(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    _key = ValueHashKey()\n",
    "    name: str\n",
    "    state: State\n",
    "\n",
    "class Address(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    \"\"\"This is address\"\"\"\n",
    "\n",
    "    _subdocument = []\n",
    "\n",
    "    street: str\n",
    "    city = City\n",
    "    postal_code: str\n",
    "    coordinates: List[Coordinates]\n",
    "\n",
    "class Brewery(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    name: str\n",
    "    type_of: Brewery_Type \n",
    "    address_of: Address\n",
    "    phone: str\n",
    "    website_url: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92700b0e",
   "metadata": {},
   "source": [
    "## Transfer data\n",
    "pandas provides built-in functions that make it simple to read and extract data from a CSV file. `read_csv` receives the path of the file as parameter, it can be a URL or a local file. Columns can be specified if not all are required, with `usecols`, `loc` method or `iloc` method.\n",
    "\n",
    "As some cells in the CSV don't have a value, when importing data it would be required to replace `NULL` values with '' if an integer or float is expected instead. `fillna` must be called to avoid `Not a number` errors.\n",
    "\n",
    "Before transfering data to TerminusDB, headers and stats of the dataset are printed, all columns in the dataset are included. Output of `df.column.values` and `df.describe(include='all')` is printed to obtain that information. \n",
    "\n",
    "Then, only required columns are selected using `loc` method and NULL values are replaced by calling `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c568230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(client, url):\n",
    "    all_breweries = []\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"HEADERS\\n\", list(df.columns.values))\n",
    "    print(\"\\nSTATS\\n\", df.describe(include='all'), \"\\n\\nPROGRESS\")\n",
    "    selection = df.loc[:, ['name', 'brewery_type', 'street', 'city', 'state', 'postal_code', 'website_url','phone', 'country', 'longitude', 'latitude']]\n",
    "    selection = selection.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63b70e",
   "metadata": {},
   "source": [
    "For importing data, a for loop is used to iterate through the values in the CSV, create objects for each document in the schema, assign values to the corresponding variables, and append these values to the `all_breweries` list. A progress bar is added with tqdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for index, row in tqdm(selection.iterrows(), total=df.shape[0], desc='Reading data'):\n",
    "        country = Country()\n",
    "        country.name = row['country']\n",
    "        state = State()\n",
    "        state.name = row['state']\n",
    "        state.country = country\n",
    "        city = City()\n",
    "        city.name = row['city']\n",
    "        city.state = state\n",
    "        address = Address()\n",
    "        address.street = row['street']\n",
    "        address.city = city\n",
    "        address.postal_code = row['postal_code']\n",
    "        address.coordinates = [str(row['longitude']), str(row['latitude'])]\n",
    "        brewery = Brewery()\n",
    "        brewery.type_of = Brewery_Type[row['brewery_type']]\n",
    "        brewery.address_of = address\n",
    "        brewery.phone = row['phone']\n",
    "        brewery.website_url = row['website_url']\n",
    "        all_breweries.append(brewery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c8cb1",
   "metadata": {},
   "source": [
    "Insert the `all_breweries` list into TerminusDB, with ``insert_document`. A progress bar is added with tdqm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df442d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with tqdm(total=1, desc='Transfering data') as pbar:\n",
    "        client.insert_document(all_breweries,\n",
    "                               commit_msg=\"Adding all breweries\")\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
