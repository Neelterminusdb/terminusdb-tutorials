{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e527090b",
   "metadata": {},
   "source": [
    "# Brewery Tutorial\n",
    "__[Open Brewery](https://www.openbrewerydb.org)__ DB is a free dataset and API with public information on breweries, cideries, brewpubs, and bottleshops. The goal of Open Brewery DB is to maintain an open-source, community-driven dataset and provide a public API. Datasets provided by the project are available in the following formats:\n",
    "- __[CSV](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.csv)__\n",
    "- __[JSON](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.json)__\n",
    "- __[PostgreSQL SQL](https://github.com/openbrewerydb/openbrewerydb/blob/master/breweries.sql)__\n",
    "\n",
    "For this tutorial, CSV will be used.\n",
    "\n",
    "TerminusDB Server must be installed on your system before running the Python script. Follow the instructions on __[terminusdb-bootstrap](https://github.com/terminusdb/terminusdb-bootstrap)__. terminusdb-server will be running as a Docker container on http://127.0.0.1:6363.\n",
    "\n",
    "Python client of TerminusDB is also required. It can be installed from source or through `pip`, you can follow the instructions in the __[repository](https://github.com/terminusdb/terminusdb-client-python)__. When running `pip install terminusdb-client[dataframe]` you will get pandas that is required for reading and importing data from CSV files. If installed from source, run `pip install pandas`. tdqm is used for adding a progress bar, run `pip install tqdm` to install it.\n",
    "\n",
    "## Import libraries\n",
    "For transfering data from a CSV file to a TerminusDB database, the Python client of TerminusDB and pandas are required. A progress bar is added to the script using tqdm. To import these libraries, add the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfec1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from terminusdb_client import WOQLQuery, WOQLClient\n",
    "from terminusdb_client.woqlschema.woql_schema import (\n",
    "    DocumentTemplate,\n",
    "    EnumTemplate,\n",
    "    WOQLSchema,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e81415",
   "metadata": {},
   "source": [
    "## Database management\n",
    "TerminusDB Server must be installed on your system before running the Python script. Follow the instructions on __[terminusdb-bootstrap](https://github.com/terminusdb/terminusdb-bootstrap)__. terminusdb-server will be running as a Docker container on http://127.0.0.1:6363.\n",
    "\n",
    "Using the Python client:\n",
    "- Establish a connection to TerminusDB\n",
    "- Create a database named *open_brewery*\n",
    "- Insert schema into database\n",
    "- Import data from CSV file\n",
    "- Print headers and stats\n",
    "- Print data from TerminusDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    db_id = \"Brewery\"\n",
    "    url = \"https://raw.githubusercontent.com/openbrewerydb/openbrewerydb/master/breweries.csv\"\n",
    "    client = WOQLClient(\"http://127.0.0.1:6363\")\n",
    "    client.connect()\n",
    "    try:\n",
    "        client.create_database(db_id, team=\"admin\", label = \"Open Brewery Graph\", description = \"Create a graph with brewery data\")\n",
    "    except Exception:\n",
    "        client.set_db(db_id)\n",
    "    client.insert_document(my_schema.to_dict(),\n",
    "                           graph_type=\"schema\",\n",
    "                           commit_msg=\"I am checking in the schema\")\n",
    "    csv_info(url)\n",
    "    insert_data(client, url)\n",
    "    results = client.get_all_documents(graph_type=\"instance\", count=10)\n",
    "    print(\"\\nRESULTS\\n\", list(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304d874",
   "metadata": {},
   "source": [
    "## Schema creation\n",
    "The dataset has the following columns:\n",
    "- obdb_id\n",
    "- name\n",
    "- brewery_type\n",
    "- street\n",
    "- address_2\n",
    "- address_3\n",
    "- city\n",
    "- state\n",
    "- county_province\n",
    "- postal_code\n",
    "- website_url\n",
    "- phone\n",
    "- created_at\n",
    "- updated_at\n",
    "- country\n",
    "- longitude\n",
    "- latitude\n",
    "- tags\n",
    "\n",
    "Some of which are optional and rarely have a value assigned and can be omitted when creating the schema and importing the values.\n",
    "\n",
    "Analyzing the dataset:\n",
    "\n",
    "- A brewery has *name*, *type*, *address*, *phone* and *website url*\n",
    "- A brewery can be any of eleven different types (micro, nano, regional, brewpub, large, planning, bar, contract, proprietor, closed, taproom)\n",
    "- An address is a group of values that include *street*, *city*, *state*, *country*, *postal code* and *coordinates*\n",
    "- Coordinates are a pair of values, longitude and latitude\n",
    "\n",
    "Based on what's described above, the following documents are created, each class represents a document in the schema except Brewery Type that is an enum:\n",
    "- Brewery\n",
    "- Brewrey_Type\n",
    "- Address\n",
    "- City\n",
    "- State\n",
    "- Country\n",
    "- Coordinates\n",
    "\n",
    "`my_schema` is a `WOQLSchema` object that contains the schema itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ca97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = WOQLSchema()\n",
    "\n",
    "class Address(DocumentTemplate):\n",
    "    \"\"\"This is address\"\"\"\n",
    "\n",
    "    _subdocument = []\n",
    "    _schema = my_schema\n",
    "    city: \"City\"\n",
    "    state: Optional[\"State\"]\n",
    "    country: \"Country\"\n",
    "    coordinates: List[\"Coordinates\"]\n",
    "    postal_code: str\n",
    "    street: str\n",
    "\n",
    "class Brewery(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    address_of: \"Address\"\n",
    "    name: str\n",
    "    phone: str\n",
    "    type_of: \"Brewery_Type\"\n",
    "    website_url: str\n",
    "\n",
    "class Brewery_Type(EnumTemplate):\n",
    "    _schema = my_schema\n",
    "    micro = ()\n",
    "    nano = ()\n",
    "    regional = ()\n",
    "    brewpub = ()\n",
    "    large = ()\n",
    "    planning = ()\n",
    "    bar = ()\n",
    "    contract = ()\n",
    "    proprietor = ()\n",
    "    closed = ()\n",
    "    taproom = ()\n",
    "\n",
    "class City(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    name: str\n",
    "\n",
    "class Coordinates(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "\n",
    "class Country(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    name: str\n",
    "\n",
    "class State(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145ffe1",
   "metadata": {},
   "source": [
    "## Print CSV info\n",
    "Before transfering data to TerminusDB, headers and stats of the dataset are printed by calling `csv_info` function. Output of `df.info()` is printed to obtain that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4879d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_info(url):\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"\\nSTATS:\\n\")\n",
    "    df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92700b0e",
   "metadata": {},
   "source": [
    "## Transfer data\n",
    "pandas provides built-in functions that make it simple to read and extract data from a CSV file. `read_csv` receives the path of the file as parameter, it can be a URL or a local file. Columns can be specified if not all are required, with `usecols` paramter in `read_csv` method.\n",
    "\n",
    "To avoid `Connection timed out`, data from CSV is read in chunks with `chunksize` parameter in `read_csv` method.\n",
    "\n",
    "As the dataset has about eight thousand registries, data is divided into 8 chunks as `chunksize` is equal to `1000`.\n",
    "\n",
    "Every chunk is saved as temporary CSV files and passed to `read_data` function that returns a list with data that is inserted into TerminusDB through `Ã¬nsert_document` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c568230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(client, url):\n",
    "    df = pd.read_csv(url, chunksize=1000, usecols = ['name', 'brewery_type', 'street', 'city', 'state', 'postal_code', 'website_url', 'phone', 'country', 'longitude', 'latitude'])\n",
    "    for chunk in tqdm(df, desc='Transfering data'):\n",
    "        csv = tempfile.NamedTemporaryFile()\n",
    "        chunk.to_csv(csv)\n",
    "        breweries = read_data(csv.name)\n",
    "        client.insert_document(breweries,\n",
    "                               commit_msg=\"Adding all breweries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63b70e",
   "metadata": {},
   "source": [
    "As some cells in the CSV don't have a value, when importing data it would be required to replace `NULL` values with '' if an integer or float is expected instead. `fillna` must be called to avoid `Not a number` errors.\n",
    "\n",
    "For importing data, a for loop is used to iterate through the values in the CSV, create objects for each document in the schema, assign values to the corresponding variables, and append these values to the `breweries` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    breweries = []\n",
    "    df = pd.read_csv(csv)\n",
    "    selection = df.fillna('')\n",
    "    for index, row in selection.iterrows():\n",
    "        # City\n",
    "        city = City()\n",
    "        city.name = row['city']\n",
    "        breweries.append(city)\n",
    "\n",
    "        # State\n",
    "        state = State()\n",
    "        state.name = row['state']\n",
    "        breweries.append(state)\n",
    "\n",
    "        # Country\n",
    "        country = Country()\n",
    "        country.name = row['country']\n",
    "        breweries.append(country)\n",
    "        \n",
    "        # Coordinates\n",
    "        coordinates = Coordinates()\n",
    "        coordinates.latitude = 0 if row['latitude']=='' else row['latitude']\n",
    "        coordinates.longitude = 0 if row['longitude']=='' else row['longitude']\n",
    "        breweries.append(coordinates)\n",
    "\n",
    "        # Address\n",
    "        address = Address()\n",
    "        address.street = row['street']\n",
    "        address.city = city\n",
    "        address.state = state\n",
    "        address.country = country\n",
    "        address.postal_code = row['postal_code']\n",
    "        address.coordinates = [coordinates]\n",
    "        breweries.append(address)\n",
    "\n",
    "        # Brewery\n",
    "        brewery = Brewery()\n",
    "        brewery.name = row['name']\n",
    "        brewery.type_of = Brewery_Type[row['brewery_type']]\n",
    "        brewery.address_of = address\n",
    "        brewery.phone = str(row['phone'])\n",
    "        brewery.website_url = row['website_url']\n",
    "        breweries.append(brewery)\n",
    "    \n",
    "    return breweries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
