{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6718ab69",
   "metadata": {},
   "source": [
    "[A Netflix dataset](https://www.kaggle.com/shivamb/netflix-shows), available as CSV file, will be imported into TerminusDB using the Python client. Instructions to install Python client can be found in the [repository](https://github.com/terminusdb/terminusdb-client-python).\n",
    "\n",
    "## Importing libraries\n",
    "Required libraries must be imported at first, including:\n",
    "\n",
    "- TerminusDB (Python client)\n",
    "- pandas\n",
    "- tqdm\n",
    "- tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a542596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from terminusdb_client import WOQLQuery, WOQLClient\n",
    "from terminusdb_client.woqlschema.woql_schema import (\n",
    "    DocumentTemplate,\n",
    "    EnumTemplate,\n",
    "    WOQLSchema,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a34f97",
   "metadata": {},
   "source": [
    "## Schema definition\n",
    "Once columns in the dataset are identified, schema must be created based on that information. Netflix dataset contains the following columns:\n",
    "\n",
    "- title\n",
    "- type\n",
    "- director\n",
    "- cast\n",
    "- country\n",
    "- release_year\n",
    "- rating\n",
    "- duration\n",
    "- listed_in\n",
    "- description\n",
    "- date_added\n",
    "\n",
    "From which there would be one main class, `Netflix`, one subdocument, `Country` and two Enums, `Content_Type` and `Rating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = WOQLSchema()\n",
    "\n",
    "class Netflix(DocumentTemplate):\n",
    "    _schema = my_schema\n",
    "    title: str\n",
    "    type_of: \"Content_Type\"\n",
    "    director: str\n",
    "    cast: str\n",
    "    country: \"Country\"\n",
    "    release_year: int\n",
    "    rating: \"Rating\"\n",
    "    duration: str\n",
    "    listed_in: str\n",
    "    description: str\n",
    "    date_added: str\n",
    "\n",
    "class Content_Type(EnumTemplate):\n",
    "    _schema = my_schema\n",
    "    TV_Show = \"TV Show\"\n",
    "    Movie = \"Movie\"\n",
    "\n",
    "class Rating(EnumTemplate):\n",
    "    _schema = my_schema\n",
    "    TV_MA = \"TV-MA\"\n",
    "    R = ()\n",
    "    PG_13 = \"PG-13\"\n",
    "    TV_14 = \"TV-14\"\n",
    "    TV_PG = \"TV-PG\"\n",
    "    NR = ()\n",
    "    TV_G = \"TV-G\"\n",
    "    TV_Y = \"TV-Y\"\n",
    "    TV_Y7 = \"TV-Y7\"\n",
    "    TY = ()\n",
    "    TY_7 = \"TY-7\"\n",
    "    PG = ()\n",
    "    G = ()\n",
    "    NC_17 = \"NC-17\"\n",
    "    TV_Y7_FV = \"TV-Y7-FV\"\n",
    "    UR = ()\n",
    "\n",
    "class Country(DocumentTemplate):\n",
    "    _subdocument = []\n",
    "    _schema = my_schema\n",
    "    name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef07f7",
   "metadata": {},
   "source": [
    "## Reading and importing data\n",
    "Dataset will be read using `pandas`and inserted into TerminusDB by calling the `insert_data` fucntion. To avoid `Connection Timed Out` errors, dataset will be read in chunks. Every chunk will be processed individually through the `read_data` function, where some additional validations will be made before importing the data and `NA` values will be replaced with `''`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36465c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(client, url):\n",
    "    df = pd.read_csv(url, chunksize=1000)\n",
    "    for chunk in tqdm(df, desc='Transfering data'):\n",
    "        csv = tempfile.NamedTemporaryFile()\n",
    "        chunk.to_csv(csv)\n",
    "        netflix_content = read_data(csv.name)\n",
    "        client.insert_document(netflix_content,\n",
    "                               commit_msg=\"Adding all Netflix content\")\n",
    "\n",
    "def read_data(csv):\n",
    "    records = []\n",
    "    df = pd.read_csv(csv)\n",
    "    selection = df.fillna('')\n",
    "    for index, row in selection.iterrows():\n",
    "\n",
    "        type_of = row['type'].replace(\" \", \"_\")\n",
    "        rating = \"NR\" if row['rating'] == \"\" else row['rating'].replace(\"-\", \"_\")\n",
    "\n",
    "        #Country\n",
    "        country = Country()\n",
    "        country.name = row['country']\n",
    "        records.append(country)\n",
    "\n",
    "        # Netflix\n",
    "        netflix = Netflix()\n",
    "        netflix.title = row['title']\n",
    "        netflix.type_of = Content_Type[type_of]\n",
    "        netflix.director = row['director']\n",
    "        netflix.cast = row['cast']\n",
    "        netflix.country = country\n",
    "        netflix.release_year = row['release_year']\n",
    "        netflix.rating = Rating[rating]\n",
    "        netflix.duration = row['duration']\n",
    "        netflix.listed_in = row['listed_in']\n",
    "        netflix.description = row['description']\n",
    "        netflix.date_added = row['date_added']\n",
    "        records.append(netflix)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c57f97",
   "metadata": {},
   "source": [
    "## Database connection\n",
    "You must established a connection to either a local instance of TerminusDB Server (running at http://127.0.0.1:6363) or a TerminusX account, then create a database named `Netflix`. The schema defined above is inserted into TerminusDB by calling the `insert_document` method defined in the Python client. Finally, `insert data` function is called and first 10 records of the `Netfix` database are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c219804",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    db_id = \"Netflix\"\n",
    "    url = \"netflix.csv\"\n",
    "    #client = WOQLClient(\"http://127.0.0.1:6363\")\n",
    "    #client.connect()\n",
    "\n",
    "    team = \"team\"\n",
    "    client = WOQLClient(\"https://cloud.terminusdb.com/team/\")\n",
    "\n",
    "    client.connect(team=team, use_token=True)\n",
    "    \n",
    "    try:\n",
    "        client.create_database(db_id, team=team, label = \"Netflix Graph\", description = \"Create a graph with Netflix data\")\n",
    "    except Exception:\n",
    "        client.set_db(db_id)\n",
    "    client.insert_document(my_schema.to_dict(),\n",
    "                           graph_type=\"schema\",\n",
    "                           commit_msg=\"I am checking in the schema\")\n",
    "    insert_data(client, url)\n",
    "    results = client.get_all_documents(graph_type=\"instance\", count=10)\n",
    "    print(\"\\nRESULTS\\n\", list(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
